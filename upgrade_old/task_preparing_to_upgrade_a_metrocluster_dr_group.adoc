---
permalink: upgrade/task_preparing_to_upgrade_a_metrocluster_dr_group.html
sidebar: sidebar
keywords: 
summary: 'Before you actually update the software on the nodes, you must identify the DR relationships among the nodes, send an AutoSupport message that you are initiating an update, and confirm the ONTAP version running on each node.'
---
= Preparing to update a MetroCluster DR group
:icons: font
:imagesdir: ../media/

[.lead]
Before you actually update the software on the nodes, you must identify the DR relationships among the nodes, send an AutoSupport message that you are initiating an update, and confirm the ONTAP version running on each node.

You must have installed the software images.

link:task_installing_ontap_software_images.md#[Installing the ONTAP software image]

This task must be repeated on each DR group. If the MetroCluster configuration consists of eight nodes, there are two DR groups. Thereby, this task must be repeated on each DR group.

The examples provided in this task use the names shown in the following illustration to identify the clusters and nodes:

image::../media/mcc_dr_groups_8_node.gif[]

. Identify the DR pairs in the configuration: `metrocluster node show -fields dr-partner`
+
----
cluster_A::> metrocluster node show -fields dr-partner
  (metrocluster node show)
dr-group-id cluster     node       dr-partner
----------- -------     --------   ----------
1           cluster_A   node_A_1   node_B_1
1           cluster_A   node_A_2   node_B_2
1           cluster_B   node_B_1   node_A_1
1           cluster_B   node_B_2   node_A_2
4 entries were displayed.

cluster_A::>
----

. Set the privilege level from admin to advanced, entering *y* when prompted to continue: `set -privilege advanced`
+
The advanced prompt (`*>`) appears.

. Confirm the ONTAP version running on each node:
 .. Confirm the version on cluster_A: `system image show`
+
----
cluster_A::*> system image show
                 Is      Is                Install
Node     Image   Default Current Version   Date
-------- ------- ------- ------- -------   -------------------
node_A_1
         image1  true    true    X.X.X     MM/DD/YYYY TIME
         image2  false   false   Y.Y.Y     MM/DD/YYYY TIME
node_A_2
         image1  true    true    X.X.X     MM/DD/YYYY TIME
         image2  false   false   Y.Y.Y     MM/DD/YYYY TIME
4 entries were displayed.

cluster_A::>
----

 .. Confirm the version on cluster_B: `system image show`
+
----
cluster_B::*> system image show
                 Is      Is                 Install
Node     Image   Default Current Version    Date
-------- ------- ------- ------- -------    -------------------
node_B_1
         image1  true    true    X.X.X      MM/DD/YYYY TIME
         image2  false   false   Y.Y.Y      MM/DD/YYYY TIME
node_B_2
         image1  true    true    X.X.X      MM/DD/YYYY TIME
         image2  false   false   Y.Y.Y      MM/DD/YYYY TIME
4 entries were displayed.

cluster_B::>
----
. Trigger an AutoSupport notification: `autosupport invoke -node * -type all -message "Starting_NDU"`
+
This AutoSupport notification includes a record of the system status before the update. It saves useful troubleshooting information if there is a problem with the update process.
+
If your cluster is not configured to send AutoSupport messages, then a copy of the notification is saved locally.

. For each node in the first set, set the target ONTAP software image to be the default image: `system image modify {-node nodename -iscurrent false} -isdefault true`
+
This command uses an extended query to change the target software image, which is installed as the alternate image, to be the default image for the node.

. Verify that the target ONTAP software image is set as the default image:
 .. Verify the images on cluster_A: `system image show`
+
In the following example, image2 is the new ONTAP version and is set as the default image on each of the nodes in the first set:
+
----
cluster_A::*> system image show
                 Is      Is              Install
Node     Image   Default Current Version Date
-------- ------- ------- ------- ------- -------------------
node_A_1
         image1  false   true    X.X.X   MM/DD/YYYY TIME
         image2  true    false   Y.Y.Y   MM/DD/YYYY TIME
node_A_2
         image1  false   true    X.X.X   MM/DD/YYYY TIME
         image2  true   false   Y.Y.Y   MM/DD/YYYY TIME

2 entries were displayed.
----

 .. Verify the images on cluster_B: `system image show`
+
The following example shows that the target version is set as the default image on each of the nodes in the first set:
+
----
cluster_B::*> system image show
                 Is      Is              Install
Node     Image   Default Current Version Date
-------- ------- ------- ------- ------- -------------------
node_A_1
         image1  false   true    X.X.X   MM/DD/YYYY TIME
         image2  true    false   Y.Y.Y   MM/YY/YYYY TIME
node_A_2
         image1  false   true    X.X.X   MM/DD/YYYY TIME
         image2  true    false   Y.Y.Y   MM/DD/YYYY TIME

2 entries were displayed.
----
. Determine whether the nodes to be upgraded are currently serving any clients by entering the following command twice for each node: `system node run -node target-node -command uptime`
+
The uptime command displays the total number of operations that the node has performed for NFS, CIFS, FC, and iSCSI clients since the node was last booted. For each protocol, you need to run the command twice to determine whether the operation counts are increasing. If they are increasing, the node is currently serving clients for that protocol. If they are not increasing, the node is not currently serving clients for that protocol.
+
NOTE: You should make a note of each protocol that has increasing client operations so that after the node is upgraded, you can verify that client traffic has resumed.
+
This example shows a node with NFS, CIFS, FC, and iSCSI operations. However, the node is currently serving only NFS and iSCSI clients.
+
----
cluster_x::> system node run -node node0 -command uptime
  2:58pm up  7 days, 19:16 800000260 NFS ops, 1017333 CIFS ops, 0 HTTP ops, 40395 FCP ops, 32810 iSCSI ops

cluster_x::> system node run -node node0 -command uptime
  2:58pm up  7 days, 19:17 800001573 NFS ops, 1017333 CIFS ops, 0 HTTP ops, 40395 FCP ops, 32815 iSCSI ops
----
