---
permalink: disks-aggregates/expand-aggregates-task.html
sidebar: sidebar
keywords: expand, aggregate
summary: "You can add disks to an aggregate so that it can provide more storage to its associated volumes. The procedure for adding partitioned disks to an aggregate is similar to the procedure for adding unpartitioned disks."
---
= Expand aggregates
:icons: font
:imagesdir: ../media/

[.lead]
You can add disks to an aggregate so that it can provide more storage to its associated volumes. The procedure for adding partitioned disks to an aggregate is similar to the procedure for adding unpartitioned disks.

.What you'll need

You must know what the RAID group size is for the aggregate you are adding the storage to.

.About this task

When you expand an aggregate, you should be aware of whether you are adding partition or unpartitioned disks to the aggregate. When you add unpartitioned drives to an existing aggregate, the size of the existing RAID groups is inherited by the new RAID group, which can affect the number of parity disks required. If an unpartitioned disk is added to a RAID group composed of partitioned disks, the new disk is partitioned, leaving an unused spare partition.

When you provision partitions, you must ensure that you do not leave the node without a drive with both partitions as spare. If you do, and the node experiences a controller disruption, valuable information about the problem (the core file) might not be available to provide to the technical support.

[NOTE]
====
Do not use the `disklist` command to expand your aggregates. This could cause partition misalignment.
====

.Steps

. Show the available spare storage on the system that owns the aggregate:
+
`storage aggregate show-spare-disks -original-owner _node_name_`
+
You can use the `-is-disk-shared` parameter to show only partitioned drives or only unpartitioned drives.
+
----
cl1-s2::> storage aggregate show-spare-disks -original-owner cl1-s2 -is-disk-shared true

Original Owner: cl1-s2
 Pool0
  Shared HDD Spares
                                                            Local    Local
                                                             Data     Root Physical
 Disk                        Type     RPM Checksum         Usable   Usable     Size Status
 --------------------------- ----- ------ -------------- -------- -------- -------- --------
 1.0.1                       BSAS    7200 block           753.8GB  73.89GB  828.0GB zeroed
 1.0.2                       BSAS    7200 block           753.8GB       0B  828.0GB zeroed
 1.0.3                       BSAS    7200 block           753.8GB       0B  828.0GB zeroed
 1.0.4                       BSAS    7200 block           753.8GB       0B  828.0GB zeroed
 1.0.8                       BSAS    7200 block           753.8GB       0B  828.0GB zeroed
 1.0.9                       BSAS    7200 block           753.8GB       0B  828.0GB zeroed
 1.0.10                      BSAS    7200 block                0B  73.89GB  828.0GB zeroed
2 entries were displayed.
----

. Show the current RAID groups for the aggregate:
+
`storage aggregate show-status _aggr_name_`
+
----
cl1-s2::> storage aggregate show-status -aggregate data_1

Owner Node: cl1-s2
 Aggregate: data_1 (online, raid_dp) (block checksums)
  Plex: /data_1/plex0 (online, normal, active, pool0)
   RAID Group /data_1/plex0/rg0 (normal, block checksums)
                                                              Usable Physical
     Position Disk                        Pool Type     RPM     Size     Size Status
     -------- --------------------------- ---- ----- ------ -------- -------- ----------
     shared   1.0.10                       0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.5                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.6                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.11                       0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.0                        0   BSAS    7200  753.8GB  828.0GB (normal)
5 entries were displayed.
----

. Simulate adding the storage to the aggregate:
+
`storage aggregate add-disks -aggregate _aggr_name_ -diskcount _number_of_disks_or_partitions_ -simulate true`
+
You can see the result of the storage addition without actually provisioning any storage. If any warnings are displayed from the simulated command, you can adjust the command and repeat the simulation.
+
----
cl1-s2::> storage aggregate add-disks data_1 -diskcount 5 -simulate true

Addition of disks would succeed for aggregate "data_1" on node "cl1-s2". The
following disks would be used to add to the aggregate: 1.0.2, 1.0.3, 1.0.4, 1.0.8, 1.0.9.
----

. Add the storage to the aggregate:
+
`storage aggregate add-disks -aggregate _aggr_name_ -raidgroup new -diskcount _number_of_disks_or_partitions_`
+
When creating a Flash Pool aggregate, if you are adding disks with a different checksum than the aggregate, or if you are adding disks to a mixed checksum aggregate, you must use the `-checksumstyle` parameter.
+
If you are adding disks to a Flash Pool aggregate, you must use the `-disktype` parameter to specify the disk type.
+
You can use the `-disksize` parameter to specify a size of the disks to add. Only disks with approximately the specified size are selected for addition to the aggregate.
+
----
cl1-s2::> storage aggregate add-disks -aggregate data_1 -raidgroup new -diskcount 5
----

. Verify that the storage was added successfully:
+
`storage aggregate show-status -aggregate _aggr_name_`
+
----
cl1-s2::> storage aggregate show-status -aggregate data_1

Owner Node: cl1-s2
 Aggregate: data_1 (online, raid_dp) (block checksums)
  Plex: /data_1/plex0 (online, normal, active, pool0)
   RAID Group /data_1/plex0/rg0 (normal, block checksums)
                                                              Usable Physical
     Position Disk                        Pool Type     RPM     Size     Size Status
     -------- --------------------------- ---- ----- ------ -------- -------- ----------
     shared   1.0.10                       0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.5                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.6                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.11                       0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.0                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.2                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.3                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.4                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.8                        0   BSAS    7200  753.8GB  828.0GB (normal)
     shared   1.0.9                        0   BSAS    7200  753.8GB  828.0GB (normal)
10 entries were displayed.
----

. Verify that the node still has at least one drive with both the root partition and the data partition as spare:
+
`storage aggregate show-spare-disks -original-owner _node_name_`
+
----
cl1-s2::> storage aggregate show-spare-disks -original-owner cl1-s2 -is-disk-shared true

Original Owner: cl1-s2
 Pool0
  Shared HDD Spares
                                                            Local    Local
                                                             Data     Root Physical
 Disk                        Type     RPM Checksum         Usable   Usable     Size Status
 --------------------------- ----- ------ -------------- -------- -------- -------- --------
 1.0.1                       BSAS    7200 block           753.8GB  73.89GB  828.0GB zeroed
 1.0.10                      BSAS    7200 block                0B  73.89GB  828.0GB zeroed
2 entries were displayed.
----
