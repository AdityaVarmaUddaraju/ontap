---
permalink: san-config/calculate-queue-depth-task.html
sidebar: sidebar
keywords: calculate, queue depth
summary: "You might need to tune your FC queue depth on the host to achieve the maximum values for ITNs per node and FC port fan-in. The maximum number of LUNs and the number of HBAs that can connect to an FC port are limited by the available queue depth on the FC target ports."
---
= Calculate queue depth overview
:icons: font
:imagesdir: ../media/

[.lead]
You might need to tune your FC queue depth on the host to achieve the maximum values for ITNs per node and FC port fan-in. The maximum number of LUNs and the number of HBAs that can connect to an FC port are limited by the available queue depth on the FC target ports.

.About this task

Queue depth is the number of I/O requests (SCSI commands) that can be queued at one time on a storage controller. Each I/O request from the host's initiator HBA to the storage controller's target adapter consumes a queue entry. Typically, a higher queue depth equates to better performance. However, if the storage controller's maximum queue depth is reached, that storage controller rejects incoming commands by returning a QFULL response to them. If a large number of hosts are accessing a storage controller, you should plan carefully to avoid QFULL conditions, which significantly degrade system performance and can lead to errors on some systems.

In a configuration with multiple initiators (hosts), all hosts should have similar queue depths. Because of the inequality in queue depth between hosts connected to the storage controller through the same target port, hosts with smaller queue depths are being deprived of access to resources by hosts with larger queue depths.

The following general recommendations can be made about "`tuning`" queue depths:

* For small to mid-size systems, use an HBA queue depth of 32.
* For large systems, use an HBA queue depth of 128.
* For exception cases or performance testing, use a queue depth of 256 to avoid possible queuing problems.
* All hosts should have the queue depths set to similar values to give equal access to all hosts.
* To avoid performance penalties or errors, the storage controller target FC port queue depth must not be exceeded.

.Steps

. Count the total number of FC initiators in all of the hosts that connect to one FC target port.
. Multiply by 128.
 ** If the result is less than 2,048, set the queue depth for all initiators to 128.
You have 15 hosts with one initiator connected to each of two target ports on the storage controller. 15 × 128 = 1,920. Because 1,920 is less than the total queue depth limit of 2,048, you can set the queue depth for all of your initiators to 128.
 ** If the result is greater than 2,048, go to step 3.
You have 30 hosts with one initiator connected to each of two target ports on the storage controller. 30 × 128 = 3,840. Because 3,840 is greater than the total queue depth limit of 2,048, you should choose one of the options under step 3 for remediation.
. Choose one of the following options to add more hosts to the storage controller.
 ** Option 1:
  ... Add more FC target ports.
  ... Redistribute your FC initiators.
  ... Repeat steps 1 and 2.
   +
  The desired queue depth of 3,840 exceeds the available queue depth per port. To remedy this, you can add a two-port FC target adapter to each controller, then rezone your FC switches so that 15 of your 30 hosts connect to one set of ports, and the remaining 15 hosts connect to a second set of ports. The queue depth per port is then reduced to 15 × 128 = 1,920.
 ** Option 2:
  ... Designate each host as "`large`" or "`small`" based on its expected I/O need.
  ... Multiply the number of large initiators by 128.
  ... Multiply the number of small initiators by 32.
  ... Add the two results together.
  ... If the result is less than 2,048, set the queue depth for large hosts to 128 and the queue depth for small hosts to 32.
  ... If the result is still greater than 2,048 per port, reduce the queue depth per initiator until the total queue depth is less than or equal to 2,048.
+
[NOTE]
====
To estimate the queue depth needed to achieve a certain I/O per second throughput, use this formula:

Needed queue depth = (Number of I/O per second) × (Response time)

For example, if you need 40,000 I/O per second with a response time of 3 milliseconds, the needed queue depth = 40,000 × (.003) = 120.
====

The maximum number of hosts that you can connect to a target port is 64, if you decide to limit the queue depth to the basic recommendation of 32. However, if you decide to have a queue depth of 128, then you can have a maximum of 16 hosts connected to one target port. The larger the queue depth, the fewer hosts that a single target port can support. If your requirement is such that you cannot compromise on the queue depth, then you should get more target ports.

The desired queue depth of 3,840 exceeds the available queue depth per port. You have 10 "`large`" hosts that have high storage I/O needs, and 20 "`small`" hosts that have low I/O needs. Set the initiator queue depth on the large hosts to 128 and the initiator queue depth on the small hosts to 32.

Your resulting total queue depth is (10 × 128) + (20 × 32) = 1,920.

You can spread the available queue depth equally across each initiator.

Your resulting queue depth per initiator is 2,048 ÷ 30 = 68.

== Set queue depths on AIX hosts

You can change the queue depth on AIX hosts using the `chdev` command. Changes made using the `chdev` command persist across reboots.

Examples:

* To change the queue depth for the hdisk7 device, use the following command:
+
`chdev -l hdisk7 -a queue_depth=32`

* To change the queue depth for the fcs0 HBA, use the following command:
+
`chdev -l fcs0 -a num_cmd_elems=128`
+
The default value for `num_cmd_elems` is 200. The maximum value is 2,048.
+
[NOTE]
====
It might be necessary to take the HBA offline to change `num_cmd_elems` and then bring it back online using the `rmdev -l fcs0 -R` and `makdev -l fcs0 -P` commands.
====

== Set queue depths on HP-UX hosts

You can change the LUN or device queue depth on HP-UX hosts using the kernel parameter `scsi_max_qdepth`. You can change the HBA queue depth using the kernel parameter `max_fcp_reqs`.

* The default value for `scsi_max_qdepth` is 8. The maximum value is 255.
+
`scsi_max_qdepth` can be dynamically changed on a running system using the `-u` option on the `kmtune` command. The change will be effective for all devices on the system. For example, use the following command to increase the LUN queue depth to 64:
+
`kmtune -u -s scsi_max_qdepth=64`
+
It is possible to change queue depth for individual device files using the `scsictl` command. Changes using the `scsictl` command are not persistent across system reboots. To view and change the queue depth for a particular device file, execute the following command:
+
`scsictl -a /dev/rdsk/c2t2d0`
+
`scsictl -m queue_depth=16 /dev/rdsk/c2t2d0`

* The default value for `max_fcp_reqs` is 512. The maximum value is 1024.
+
The kernel must be rebuilt and the system must be rebooted for changes to `max_fcp_reqs` to take effect. To change the HBA queue depth to 256, for example, use the following command:
+
`kmtune -u -s max_fcp_reqs=256`

== Set queue depths on Solaris hosts

You can set the LUN and HBA queue depth for your Solaris hosts.

* For LUN queue depth: The number of LUNs in use on a host multiplied by the per-LUN throttle (lun-queue-depth) must be less than or equal to the tgt-queue-depth value on the host.
* For queue depth in a Sun stack: The native drivers do not allow for per LUN or per target `max_throttle` settings at the HBA level. The recommended method for setting the `max_throttle` value for native drivers is on a per-device type (VID_PID) level in the `/kernel/drv/sd.conf` and `/kernel/drv/ssd.conf` files. The host utility sets this value to 64 for MPxIO configurations and 8 for Veritas DMP configurations.

.Steps

. `# cd/kernel/drv`
. `# vi lpfc.conf`
. Search for `/tft-queue (/tgt-queue)`
+
`tgt-queue-depth=32`
+
[NOTE]
====
The default value is set to 32 at installation.
====
. Set the desired value based on the configuration of your environment.
. Save the file.
. Reboot the host using the `+sync; sync; sync; reboot -- -r+` command.

== Set queue depths on VMware hosts

Use the `esxcfg-module` command to change the HBA timeout settings. Manually updating the `esx.conf` file is not recommended.

=== Set maximum queue depth for a QLogic HBA

.Steps

. Log on to the service console as the root user.
. Use the `#vmkload_mod -l` command to verify which Qlogic HBA module is currently loaded.
. For a single instance of a Qlogic HBA, run the following command:
+
`#esxcfg-module -s ql2xmaxqdepth=64 qla2300_707`
+
[NOTE]
====
This example uses qla2300_707 module. Use the appropriate module based on the output of `vmkload_mod -l`.
====

. Save your changes using the following command:
+
`#/usr/sbin/esxcfg-boot -b`
. Reboot the server using the following command:
+
`#reboot`
. Confirm the changes using the following commands:
 .. `#esxcfg-module -g qla2300_707`
 .. `qla2300_707 enabled = 1 options = 'ql2xmaxqdepth=64'`

=== Change queue depth of an Emulex HBA

.Steps

. Log on to the service console as the root user.
. Use the `#vmkload_mod -l grep lpfcdd` command to verify which Emulex HBA is currently loaded.
. For a single instance of an Emulex HBA, enter the following command:
+
`#esxcfg-module -s lpfc0_lun_queue_depth=16 lpfcdd_7xx`
+
[NOTE]
====
Depending on the model of the HBA, the module can be either lpfcdd_7xx or lpfcdd_732. The above command uses the lpfcdd_7xx module. You should use the appropriate module based on the outcome of `vmkload_mod -l`.
====
+
Running this command will set the LUN queue depth to 16 for the HBA represented by lpfc0.

. For multiple instances of an Emulex HBA, run the following command:
+
`a esxcfg-module -s "lpfc0_lun_queue_depth=16 lpfc1_lun_queue_depth=16" lpfcdd_7xx`
+
The LUN queue depth for lpfc0 and the LUN queue depth for lpfc1 is set to 16.

. Enter the following command:
+
`#esxcfg-boot -b`
. Reboot using `#reboot`.

== Set queue depths on Windows hosts

On Windows hosts, you can use the `LPUTILNT` utility to update the queue depth for Emulex HBAs and the `SANsurfer` HBA manager utility to update the queue depths for Qlogic HBAs.

=== Update Emulex HBA queue depths

.Steps

. Run the `LPUTILNT` utility located in the `C:\WINNT\system32` directory.
. Select *Drive Parameters* from the menu on the right side.
. Scroll down and double-click *QueueDepth*.
+
[NOTE]
====
If you are setting *QueueDepth* greater than 150, the following Windows Registry value also need to be increased appropriately:

`HKEY_LOCAL_MACHINE\System\CurrentControlSet\Services\lpxnds\Parameters\Device\NumberOfRequests`
====

=== Update Qlogic HBA queue depths

.Steps

. Run the `SANsurfer` HBA manager utility.
. Click on *HBA port* > *Settings*.
. Click *Advanced HBA port settings* in the list box.
. Update the `Execution Throttle` parameter.
